{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23657f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b80d388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountCases</th>\n",
       "      <th>BedDys</th>\n",
       "      <th>BeddystoCC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>DiedCases</th>\n",
       "      <th>DiedBdDys</th>\n",
       "      <th>Hsptlsns</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "      <th>Y2017</th>\n",
       "      <th>Y2018</th>\n",
       "      <th>Y2019</th>\n",
       "      <th>Y2020</th>\n",
       "      <th>Y2021</th>\n",
       "      <th>CovidPrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>133</td>\n",
       "      <td>7.823529</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>372</td>\n",
       "      <td>28.615385</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>218</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>238</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountCases  BedDys  BeddystoCC  Severity  DiedCases  DiedBdDys  Hsptlsns  \\\n",
       "0          17     133    7.823529        75          4          9        13   \n",
       "1          13     372   28.615385        63          4         34         9   \n",
       "2           8     106   13.250000        48          4         13         4   \n",
       "3          45     218    4.844444       153          3         24        42   \n",
       "4          24     238    9.916667        90          3          8        21   \n",
       "\n",
       "   April  August  December  ...  Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  \\\n",
       "0      0       0         0  ...      1      0      0      0      0      0   \n",
       "1      0       0         0  ...      0      0      0      0      0      0   \n",
       "2      0       0         0  ...      0      0      0      0      0      1   \n",
       "3      0       0         0  ...      0      0      0      1      0      0   \n",
       "4      0       1         0  ...      1      0      0      0      0      0   \n",
       "\n",
       "   Y2019  Y2020  Y2021  CovidPrd  \n",
       "0      0      0      0         0  \n",
       "1      0      0      0         0  \n",
       "2      0      0      0         0  \n",
       "3      0      0      0         0  \n",
       "4      0      0      0         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('final_with_covid_AS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7daad8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Severity'] = np.log(data['Severity'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9cf6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da6a5392",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_bins = 2\n",
    "\n",
    "bed_days_min = filtered_data['Severity'].min()\n",
    "bed_days_max = filtered_data['Severity'].max()\n",
    "\n",
    "bin_width = (bed_days_max - bed_days_min) / num_bins\n",
    "bins = [bed_days_min + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "def bin_function(x):\n",
    "    for i in range(1, len(bins)):\n",
    "        if x <= bins[i]:\n",
    "            return i - 1\n",
    "    return i\n",
    "\n",
    "filtered_data['Bed_days_category'] = filtered_data['Severity'].apply(bin_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8fa97f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    44186\n",
       "1     9852\n",
       "Name: Bed_days_category, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['Bed_days_category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4d61dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9085245497162595\n",
      "Confusion Matrix:\n",
      " [[12450   745]\n",
      " [  738  2279]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94     13195\n",
      "           1       0.75      0.76      0.75      3017\n",
      "\n",
      "    accuracy                           0.91     16212\n",
      "   macro avg       0.85      0.85      0.85     16212\n",
      "weighted avg       0.91      0.91      0.91     16212\n",
      "\n",
      "Precision: 0.7536375661375662\n",
      "Recall: 0.7553861451773285\n",
      "F1-score: 0.7545108425757325\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = filtered_data[['Age1725','Age2639','Age4064','Age6574','Age75plus',\n",
    "                   'Male',\n",
    "                   \n",
    "                   'Regional',\n",
    "\n",
    "                   'April','December','February','January','July',\n",
    "                   'June','March','May','November','October','September',\n",
    "\n",
    "                   'Cntrprt23WldMV','CntrprtFxdStnry','CntrprtHvyVhcl',\n",
    "                   'CntrprtNClsn','CntrprtOther','CntrprtNMV','CntrprtCrTrkVn',\n",
    "                   'CntrprtPdlC','CntrprtPdstAnml','CntrprtTrn',\n",
    "\n",
    "                   'Y2014','Y2015','Y2016','Y2017','Y2018','Y2019','Y2020','Y2021','BedDys',\n",
    "                   'Y2013','Y2012',\n",
    "                   'CovidPrd']]\n",
    "\n",
    "\n",
    "\n",
    "y = filtered_data['Bed_days_category']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "class_report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb) \n",
    "recall_xgb = recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb)\n",
    "\n",
    "print('Accuracy:', acc_xgb)\n",
    "print('Confusion Matrix:\\n', conf_matrix_xgb)\n",
    "print('Classification Report:\\n', class_report_xgb)\n",
    "print('Precision:', precision_xgb)\n",
    "print('Recall:', recall_xgb)\n",
    "print('F1-score:', f1_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca5c16b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceb055f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7536375661375662\n",
      "0.7553861451773285\n",
      "0.7545108425757325\n",
      "[[12450   745]\n",
      " [  738  2279]]\n",
      "0    44186\n",
      "1     9852\n",
      "Name: Bed_days_category, dtype: int64\n",
      "0.9085245497162595\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "X = filtered_data[['Age1725','Age2639','Age4064','Age6574','Age75plus',\n",
    "                   'Male',\n",
    "                   \n",
    "                   'Regional',\n",
    "\n",
    "                   'April','December','February','January','July',\n",
    "                   'June','March','May','November','October','September',\n",
    "\n",
    "                   'Cntrprt23WldMV','CntrprtFxdStnry','CntrprtHvyVhcl',\n",
    "                   'CntrprtNClsn','CntrprtOther','CntrprtNMV','CntrprtCrTrkVn',\n",
    "                   'CntrprtPdlC','CntrprtPdstAnml','CntrprtTrn',\n",
    "\n",
    "                   'Y2014','Y2015','Y2016','Y2017','Y2018','Y2019','Y2020','Y2021',\n",
    "                   'Y2013','Y2012','BedDys',\n",
    "                   'CovidPrd']]\n",
    "\n",
    "\n",
    "\n",
    "y = filtered_data['Bed_days_category']\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "xgb_model = XGBClassifier(random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "class_report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "precision_xgb = precision_score(y_test,y_pred_xgb)\n",
    "recall_xgb= recall_score(y_test, y_pred_xgb)\n",
    "f1_xgb= f1_score(y_test,y_pred_xgb)\n",
    "print(precision_xgb)\n",
    "print(recall_xgb)\n",
    "print(f1_xgb)\n",
    "print(confusion_matrix(y_true=y_test,y_pred=y_pred_xgb))\n",
    "print(y.value_counts())\n",
    "print(accuracy_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3654bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "بهترین آستانه با توجه به F1 Score: 0.3535353535353536\n",
      "مقدار F1 Score بهترین آستانه: 0.7715478675812705\n"
     ]
    }
   ],
   "source": [
    "# برای محاسبه احتمالات پیش‌بینی هر کلاس\n",
    "y_pred_proba_svm = xgb_model.predict_proba(X_test)\n",
    "# در اینجا y_pred_proba_svm یک آرایه با ابعاد (تعداد نمونه‌ها، تعداد کلاس‌ها) است\n",
    "\n",
    "# حالا برای هر آستانه ممکن احتمالات را به پیش‌بینی تبدیل می‌کنیم\n",
    "thresholds = np.linspace(0, 1, 100)\n",
    "f1_scores = []\n",
    "for threshold in thresholds:\n",
    "    y_pred_threshold = (y_pred_proba_svm[:, 1] >= threshold).astype(int)\n",
    "    f1_scores.append(f1_score(y_test, y_pred_threshold))\n",
    "\n",
    "# بهترین آستانه را با توجه به F1 Score پیدا می‌کنیم\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(\"بهترین آستانه با توجه به F1 Score:\", best_threshold)\n",
    "print(\"مقدار F1 Score بهترین آستانه:\", best_f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "571c7df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13195\n",
       "1     3017\n",
       "Name: Bed_days_category, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f5e1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# پیش از تقسیم داده‌ها به آموزش و آزمون\n",
    "ros = RandomOverSampler(random_state=42,sampling_strategy='not majority')\n",
    "X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# سپس ادامه کد با داده‌های جدید\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.3, random_state=42)\n",
    "\n",
    "# مدل‌های پایه\n",
    "base_models = [\n",
    "     XGBClassifier(objective='binary:logistic', random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    DecisionTreeClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    KNeighborsClassifier(n_neighbors=5),\n",
    "    SVC(kernel='linear', probability=True, class_weight='balanced', random_state=42),\n",
    "    GaussianNB(),\n",
    "    ExtraTreesClassifier(random_state=42),\n",
    "    MLPClassifier(hidden_layer_sizes=(64,), random_state=42),\n",
    "]\n",
    "\n",
    "# آموزش مدل‌های پایه\n",
    "for model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# ایجاد ویژگی‌های جدید از خروجی مدل‌های پایه\n",
    "X_train_meta = [model.predict_proba(X_train) for model in base_models]\n",
    "X_train_meta = np.concatenate(X_train_meta, axis=1)\n",
    "\n",
    "X_test_meta = [model.predict_proba(X_test) for model in base_models]\n",
    "X_test_meta = np.concatenate(X_test_meta, axis=1)\n",
    "\n",
    "# ایجاد و آموزش مدل متا-طبقه‌بند\n",
    "meta_model = make_pipeline(StandardScaler(), LogisticRegression(random_state=42))\n",
    "meta_model.fit(X_train_meta, y_train)\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred = meta_model.predict(X_test_meta)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred = meta_model.predict(X_test_meta)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(class_report)\n",
    "print('Accuracy:', acc)\n",
    "print('Confusion Matrix:\\n', conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ea648e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7831598008148484\n",
      "Recall: 0.573417301955585\n",
      "F1 Score: 0.6620742441637965\n",
      "Confusion Matrix:\n",
      " [[12716   479]\n",
      " [ 1287  1730]]\n",
      "Class Distribution:\n",
      " 0    44186\n",
      "1     9852\n",
      "Name: Bed_days_category, dtype: int64\n",
      "Accuracy: 0.8910683444362201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming X and y are already defined as in your code snippet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the logistic regression model\n",
    "log_reg_model = LogisticRegression(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_log_reg = log_reg_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_log_reg = accuracy_score(y_test, y_pred_log_reg)\n",
    "conf_matrix_log_reg = confusion_matrix(y_test, y_pred_log_reg)\n",
    "class_report_log_reg = classification_report(y_test, y_pred_log_reg)\n",
    "precision_log_reg = precision_score(y_test, y_pred_log_reg)\n",
    "recall_log_reg = recall_score(y_test, y_pred_log_reg)\n",
    "f1_log_reg = f1_score(y_test, y_pred_log_reg)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Precision:\", precision_log_reg)\n",
    "print(\"Recall:\", recall_log_reg)\n",
    "print(\"F1 Score:\", f1_log_reg)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=y_test, y_pred=y_pred_log_reg))\n",
    "print(\"Class Distribution:\\n\", y.value_counts())\n",
    "print(\"Accuracy:\", accuracy_log_reg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24f57806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.729175565997437\n",
      "Recall: 0.5657938349353663\n",
      "F1 Score: 0.6371780515117581\n",
      "Confusion Matrix:\n",
      " [[12561   634]\n",
      " [ 1310  1707]]\n",
      "Class Distribution:\n",
      " 0    44186\n",
      "1     9852\n",
      "Name: Bed_days_category, dtype: int64\n",
      "Accuracy: 0.8800888230940045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Assuming X and y are already defined as in your code snippet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the SVM model\n",
    "svm_model = SVC(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "svm_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_svm = accuracy_score(y_test, y_pred_svm)\n",
    "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
    "class_report_svm = classification_report(y_test, y_pred_svm)\n",
    "precision_svm = precision_score(y_test, y_pred_svm)\n",
    "recall_svm = recall_score(y_test, y_pred_svm)\n",
    "f1_svm = f1_score(y_test, y_pred_svm)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Precision:\", precision_svm)\n",
    "print(\"Recall:\", recall_svm)\n",
    "print(\"F1 Score:\", f1_svm)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=y_test, y_pred=y_pred_svm))\n",
    "print(\"Class Distribution:\\n\", y.value_counts())\n",
    "print(\"Accuracy:\", accuracy_svm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f351d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7512280701754386\n",
      "Recall: 0.7096453430560159\n",
      "F1 Score: 0.7298448951764104\n",
      "Confusion Matrix:\n",
      " [[12486   709]\n",
      " [  876  2141]]\n",
      "Class Distribution:\n",
      " 0    44186\n",
      "1     9852\n",
      "Name: Bed_days_category, dtype: int64\n",
      "Accuracy: 0.902232913890945\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Assuming X and y are already defined as in your code snippet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "conf_matrix_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "class_report_rf = classification_report(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf)\n",
    "recall_rf = recall_score(y_test, y_pred_rf)\n",
    "f1_rf = f1_score(y_test, y_pred_rf)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Precision:\", precision_rf)\n",
    "print(\"Recall:\", recall_rf)\n",
    "print(\"F1 Score:\", f1_rf)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=y_test, y_pred=y_pred_rf))\n",
    "print(\"Class Distribution:\\n\", y.value_counts())\n",
    "print(\"Accuracy:\", accuracy_rf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55f150c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.7454364420843014\n",
      "Recall: 0.7444481272787538\n",
      "F1 Score: 0.7449419568822554\n",
      "Confusion Matrix:\n",
      " [[12428   767]\n",
      " [  771  2246]]\n",
      "Class Distribution:\n",
      " 0    44186\n",
      "1     9852\n",
      "Name: Bed_days_category, dtype: int64\n",
      "Accuracy: 0.9051320009869233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Assuming X and y are already defined as in your code snippet\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Initialize the MLP classifier\n",
    "mlp_model = MLPClassifier(random_state=42)\n",
    "\n",
    "# Fit the model to the training data\n",
    "mlp_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred_mlp = mlp_model.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy_mlp = accuracy_score(y_test, y_pred_mlp)\n",
    "conf_matrix_mlp = confusion_matrix(y_test, y_pred_mlp)\n",
    "class_report_mlp = classification_report(y_test, y_pred_mlp)\n",
    "precision_mlp = precision_score(y_test, y_pred_mlp)\n",
    "recall_mlp = recall_score(y_test, y_pred_mlp)\n",
    "f1_mlp = f1_score(y_test, y_pred_mlp)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Precision:\", precision_mlp)\n",
    "print(\"Recall:\", recall_mlp)\n",
    "print(\"F1 Score:\", f1_mlp)\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_true=y_test, y_pred=y_pred_mlp))\n",
    "print(\"Class Distribution:\\n\", y.value_counts())\n",
    "print(\"Accuracy:\", accuracy_mlp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fd1dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
