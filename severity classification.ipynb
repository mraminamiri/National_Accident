{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4062126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score,recall_score,f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac1ff87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountCases</th>\n",
       "      <th>BedDys</th>\n",
       "      <th>BeddystoCC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>DiedCases</th>\n",
       "      <th>DiedBdDys</th>\n",
       "      <th>Hsptlsns</th>\n",
       "      <th>April</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>...</th>\n",
       "      <th>Y2013</th>\n",
       "      <th>Y2014</th>\n",
       "      <th>Y2015</th>\n",
       "      <th>Y2016</th>\n",
       "      <th>Y2017</th>\n",
       "      <th>Y2018</th>\n",
       "      <th>Y2019</th>\n",
       "      <th>Y2020</th>\n",
       "      <th>Y2021</th>\n",
       "      <th>CovidPrd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17</td>\n",
       "      <td>133</td>\n",
       "      <td>7.823529</td>\n",
       "      <td>75</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>372</td>\n",
       "      <td>28.615385</td>\n",
       "      <td>63</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>106</td>\n",
       "      <td>13.250000</td>\n",
       "      <td>48</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>218</td>\n",
       "      <td>4.844444</td>\n",
       "      <td>153</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>238</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CountCases  BedDys  BeddystoCC  Severity  DiedCases  DiedBdDys  Hsptlsns  \\\n",
       "0          17     133    7.823529        75          4          9        13   \n",
       "1          13     372   28.615385        63          4         34         9   \n",
       "2           8     106   13.250000        48          4         13         4   \n",
       "3          45     218    4.844444       153          3         24        42   \n",
       "4          24     238    9.916667        90          3          8        21   \n",
       "\n",
       "   April  August  December  ...  Y2013  Y2014  Y2015  Y2016  Y2017  Y2018  \\\n",
       "0      0       0         0  ...      1      0      0      0      0      0   \n",
       "1      0       0         0  ...      0      0      0      0      0      0   \n",
       "2      0       0         0  ...      0      0      0      0      0      1   \n",
       "3      0       0         0  ...      0      0      0      1      0      0   \n",
       "4      0       1         0  ...      1      0      0      0      0      0   \n",
       "\n",
       "   Y2019  Y2020  Y2021  CovidPrd  \n",
       "0      0      0      0         0  \n",
       "1      0      0      0         0  \n",
       "2      0      0      0         0  \n",
       "3      0      0      0         0  \n",
       "4      0      0      0         0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('final_with_covid_AS.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1f7da12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12582 entries, 11 to 54025\n",
      "Data columns (total 58 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   CountCases       12582 non-null  int64  \n",
      " 1   BedDys           12582 non-null  int64  \n",
      " 2   BeddystoCC       12582 non-null  float64\n",
      " 3   Severity         12582 non-null  int64  \n",
      " 4   DiedCases        12582 non-null  int64  \n",
      " 5   DiedBdDys        12582 non-null  int64  \n",
      " 6   Hsptlsns         12582 non-null  int64  \n",
      " 7   April            12582 non-null  int64  \n",
      " 8   August           12582 non-null  int64  \n",
      " 9   December         12582 non-null  int64  \n",
      " 10  February         12582 non-null  int64  \n",
      " 11  January          12582 non-null  int64  \n",
      " 12  July             12582 non-null  int64  \n",
      " 13  June             12582 non-null  int64  \n",
      " 14  March            12582 non-null  int64  \n",
      " 15  May              12582 non-null  int64  \n",
      " 16  November         12582 non-null  int64  \n",
      " 17  October          12582 non-null  int64  \n",
      " 18  September        12582 non-null  int64  \n",
      " 19  MajorCities      12582 non-null  int64  \n",
      " 20  Regional         12582 non-null  int64  \n",
      " 21  Female           12582 non-null  int64  \n",
      " 22  Male             12582 non-null  int64  \n",
      " 23  Age07            12582 non-null  int64  \n",
      " 24  Age816           12582 non-null  int64  \n",
      " 25  Age1725          12582 non-null  int64  \n",
      " 26  Age2639          12582 non-null  int64  \n",
      " 27  Age4064          12582 non-null  int64  \n",
      " 28  Age6574          12582 non-null  int64  \n",
      " 29  Age75plus        12582 non-null  int64  \n",
      " 30  CarDriver        12582 non-null  int64  \n",
      " 31  CarPngr          12582 non-null  int64  \n",
      " 32  Mtrcyclist       12582 non-null  int64  \n",
      " 33  PdlCyclist       12582 non-null  int64  \n",
      " 34  Pedestrian       12582 non-null  int64  \n",
      " 35  Cntrprt23WldMV   12582 non-null  int64  \n",
      " 36  CntrprtCrTrkVn   12582 non-null  int64  \n",
      " 37  CntrprtFxdStnry  12582 non-null  int64  \n",
      " 38  CntrprtHvyVhcl   12582 non-null  int64  \n",
      " 39  CntrprtNClsn     12582 non-null  int64  \n",
      " 40  CntrprtNA        12582 non-null  int64  \n",
      " 41  CntrprtOther     12582 non-null  int64  \n",
      " 42  CntrprtNMV       12582 non-null  int64  \n",
      " 43  CntrprtPdlC      12582 non-null  int64  \n",
      " 44  CntrprtPdstAnml  12582 non-null  int64  \n",
      " 45  CntrprtTrn       12582 non-null  int64  \n",
      " 46  Y2011            12582 non-null  int64  \n",
      " 47  Y2012            12582 non-null  int64  \n",
      " 48  Y2013            12582 non-null  int64  \n",
      " 49  Y2014            12582 non-null  int64  \n",
      " 50  Y2015            12582 non-null  int64  \n",
      " 51  Y2016            12582 non-null  int64  \n",
      " 52  Y2017            12582 non-null  int64  \n",
      " 53  Y2018            12582 non-null  int64  \n",
      " 54  Y2019            12582 non-null  int64  \n",
      " 55  Y2020            12582 non-null  int64  \n",
      " 56  Y2021            12582 non-null  int64  \n",
      " 57  CovidPrd         12582 non-null  int64  \n",
      "dtypes: float64(1), int64(57)\n",
      "memory usage: 5.7 MB\n"
     ]
    }
   ],
   "source": [
    "filtered_data = data[data['CarDriver'] == 1]\n",
    "filtered_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fab3244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/xh28kn0j7_7d5hh7fgz188940000gn/T/ipykernel_1218/3206971614.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['Bed_days_category'] = filtered_data['Severity'].apply(bin_function)\n"
     ]
    }
   ],
   "source": [
    "num_bins = 3\n",
    "\n",
    "bed_days_min = filtered_data['Severity'].min()\n",
    "bed_days_max = filtered_data['Severity'].max()\n",
    "\n",
    "bin_width = (bed_days_max - bed_days_min) / num_bins\n",
    "bins = [bed_days_min + i * bin_width for i in range(num_bins + 1)]\n",
    "\n",
    "def bin_function(x):\n",
    "    for i in range(1, len(bins)):\n",
    "        if x <= bins[i]:\n",
    "            return i - 1\n",
    "    return i\n",
    "\n",
    "filtered_data['Bed_days_category'] = filtered_data['Severity'].apply(bin_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23636001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0]\n",
      "0    11983\n",
      "1      495\n",
      "2      104\n",
      "Name: Bed_days_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(filtered_data['Bed_days_category'].unique())\n",
    "print(filtered_data['Bed_days_category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d1cce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9825188716726262\n",
      "Confusion Matrix:\n",
      " [[2381   13    0]\n",
      " [  15   83    7]\n",
      " [   0    9    9]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2394\n",
      "           1       0.79      0.79      0.79       105\n",
      "           2       0.56      0.50      0.53        18\n",
      "\n",
      "    accuracy                           0.98      2517\n",
      "   macro avg       0.78      0.76      0.77      2517\n",
      "weighted avg       0.98      0.98      0.98      2517\n",
      "\n",
      "Precision: 0.9821762101184399\n",
      "Recall: 0.9825188716726262\n",
      "F1-score: 0.9823342301454859\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, f1_score\n",
    "\n",
    "# تقسیم‌بندی داده‌ها به ورودی و خروجی\n",
    "\n",
    "\n",
    "# تقسیم داده‌ها به مجموعه‌های آموزش و آزمون\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ایجاد و آموزش مدل XGBoost\n",
    "model = XGBClassifier(objective='multi:softprob', num_class=3, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred_xgb = model.predict(X_test)\n",
    "acc_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "conf_matrix_xgb = confusion_matrix(y_test, y_pred_xgb)\n",
    "class_report_xgb = classification_report(y_test, y_pred_xgb)\n",
    "\n",
    "precision_xgb = precision_score(y_test, y_pred_xgb, average='weighted') \n",
    "recall_xgb = recall_score(y_test, y_pred_xgb, average='weighted')\n",
    "f1_xgb = f1_score(y_test, y_pred_xgb, average='weighted')\n",
    "\n",
    "print('Accuracy:', acc_xgb)\n",
    "print('Confusion Matrix:\\n', conf_matrix_xgb)\n",
    "print('Classification Report:\\n', class_report_xgb)\n",
    "print('Precision:', precision_xgb)\n",
    "print('Recall:', recall_xgb)\n",
    "print('F1-score:', f1_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "085a346b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99      2394\n",
      "           1       0.60      0.89      0.72       105\n",
      "           2       0.48      0.67      0.56        18\n",
      "\n",
      "    accuracy                           0.97      2517\n",
      "   macro avg       0.69      0.84      0.75      2517\n",
      "weighted avg       0.98      0.97      0.97      2517\n",
      "\n",
      "0.9718992173135605\n"
     ]
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smoteenn = SMOTEENN(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smoteenn.fit_resample(X_train, y_train)\n",
    "\n",
    "model = XGBClassifier(objective='multi:softprob', num_class=3, random_state=42)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0418b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9793404847040127\n",
      "Confusion Matrix:\n",
      " [[2383   11    0]\n",
      " [  26   74    5]\n",
      " [   0   10    8]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99      2394\n",
      "           1       0.78      0.70      0.74       105\n",
      "           2       0.62      0.44      0.52        18\n",
      "\n",
      "    accuracy                           0.98      2517\n",
      "   macro avg       0.79      0.71      0.75      2517\n",
      "weighted avg       0.98      0.98      0.98      2517\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# تقسیم داده‌ها به مجموعه‌های آموزش و آزمون\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# مدل‌های پایه\n",
    "base_models = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42)\n",
    "]\n",
    "\n",
    "# آموزش مدل‌های پایه\n",
    "for model in base_models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# ایجاد ویژگی‌های جدید از خروجی مدل‌های پایه\n",
    "X_train_meta = [model.predict_proba(X_train) for model in base_models]\n",
    "X_train_meta = np.concatenate(X_train_meta, axis=1)\n",
    "\n",
    "X_test_meta = [model.predict_proba(X_test) for model in base_models]\n",
    "X_test_meta = np.concatenate(X_test_meta, axis=1)\n",
    "\n",
    "# ایجاد و آموزش مدل متا-طبقه‌بند\n",
    "meta_model = make_pipeline(StandardScaler(), LogisticRegression(random_state=42))\n",
    "meta_model.fit(X_train_meta, y_train)\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred = meta_model.predict(X_test_meta)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85930219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9725864123957092\n",
      "Confusion Matrix:\n",
      " [[2375   16    3]\n",
      " [  36   62    7]\n",
      " [   2    5   11]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2394\n",
      "           1       0.75      0.59      0.66       105\n",
      "           2       0.52      0.61      0.56        18\n",
      "\n",
      "    accuracy                           0.97      2517\n",
      "   macro avg       0.75      0.73      0.74      2517\n",
      "weighted avg       0.97      0.97      0.97      2517\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amin/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# تقسیم داده‌ها به مجموعه‌های آموزش و آزمون\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# مدل‌های پایه\n",
    "base_models = [\n",
    "    LogisticRegression(random_state=42),\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "]\n",
    "\n",
    "# آموزش مدل‌های پایه\n",
    "for model in base_models:\n",
    "    model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# ایجاد ویژگی‌های جدید از خروجی مدل‌های پایه\n",
    "X_train_meta = [model.predict_proba(X_train) for model in base_models]\n",
    "X_train_meta = np.concatenate(X_train_meta, axis=1)\n",
    "\n",
    "X_test_meta = [model.predict_proba(X_test) for model in base_models]\n",
    "X_test_meta = np.concatenate(X_test_meta, axis=1)\n",
    "\n",
    "# ایجاد و آموزش مدل متا-طبقه‌بند\n",
    "meta_model = make_pipeline(StandardScaler(), LogisticRegression(random_state=42))\n",
    "meta_model.fit(X_train_meta, y_train)\n",
    "\n",
    "# ارزیابی مدل\n",
    "y_pred = meta_model.predict(X_test_meta)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print('Accuracy:', acc)\n",
    "print('Confusion Matrix:\\n', conf_matrix)\n",
    "print('Classification Report:\\n', class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd186f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
